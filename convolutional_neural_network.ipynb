{"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3903,"status":"ok","timestamp":1707418594156,"user":{"displayName":"Kaïs Bhir","userId":"11316076557437530340"},"user_tz":-60},"id":"sCV30xyVhFbE"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1707418595413,"user":{"displayName":"Kaïs Bhir","userId":"11316076557437530340"},"user_tz":-60},"id":"FIleuCAjoFD8","outputId":"519539e1-27e4-4201-f195-b031ebb91da1"},"outputs":[{"data":{"text/plain":["'2.17.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"executionInfo":{"elapsed":14,"status":"error","timestamp":1697658532360,"user":{"displayName":"Kaïs Bhir","userId":"11316076557437530340"},"user_tz":-60},"id":"0koUcJMJpEBD","outputId":"3f2ac7cc-3689-4a8a-c9b3-f2ad5329fed6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 8000 images belonging to 2 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","training_set = train_datagen.flow_from_directory('dataset/training_set',\n","                                                 target_size = (64, 64),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'binary')"]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"SH4WzfOhpKc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2000 images belonging to 2 classes.\n"]}],"source":["test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory('dataset/test_set',\n","                                            target_size = (64, 64),\n","                                            batch_size = 32,\n","                                            class_mode = 'binary')"]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX"},"source":["### Initialising the CNN"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SAUt4UMPlhLS"},"outputs":[],"source":["cnn = tf.keras.models.Sequential()"]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XPzPrMckl-hV"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\monia\\Desktop\\Data Science Kais\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ncpqPl69mOac"},"outputs":[],"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"i_-FZjn_m8gk"},"outputs":[],"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"6AZeOGCvnNZn"},"outputs":[],"source":["cnn.add(tf.keras.layers.Flatten())"]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"8GtmUlLd26Nq"},"outputs":[],"source":["cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"1p_Zj1Mc3Ko_"},"outputs":[],"source":["cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i"},"source":["### Compiling the CNN"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"NALksrNQpUlJ"},"outputs":[],"source":["cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"XUj1W4PJptta"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\monia\\Desktop\\Data Science Kais\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5221 - loss: 0.7010"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\monia\\Desktop\\Data Science Kais\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 71ms/step - accuracy: 0.5222 - loss: 0.7009 - val_accuracy: 0.6220 - val_loss: 0.6684\n","Epoch 2/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - accuracy: 0.6176 - loss: 0.6524 - val_accuracy: 0.6420 - val_loss: 0.6365\n","Epoch 3/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 68ms/step - accuracy: 0.6724 - loss: 0.6040 - val_accuracy: 0.7020 - val_loss: 0.5886\n","Epoch 4/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 71ms/step - accuracy: 0.6990 - loss: 0.5753 - val_accuracy: 0.7250 - val_loss: 0.5538\n","Epoch 5/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 104ms/step - accuracy: 0.7237 - loss: 0.5486 - val_accuracy: 0.7420 - val_loss: 0.5333\n","Epoch 6/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 76ms/step - accuracy: 0.7428 - loss: 0.5175 - val_accuracy: 0.7360 - val_loss: 0.5336\n","Epoch 7/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 79ms/step - accuracy: 0.7504 - loss: 0.5041 - val_accuracy: 0.7560 - val_loss: 0.5001\n","Epoch 8/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 78ms/step - accuracy: 0.7710 - loss: 0.4660 - val_accuracy: 0.7655 - val_loss: 0.4927\n","Epoch 9/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 79ms/step - accuracy: 0.7862 - loss: 0.4540 - val_accuracy: 0.7695 - val_loss: 0.4920\n","Epoch 10/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 81ms/step - accuracy: 0.8038 - loss: 0.4246 - val_accuracy: 0.7625 - val_loss: 0.5197\n","Epoch 11/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 86ms/step - accuracy: 0.8109 - loss: 0.4074 - val_accuracy: 0.7925 - val_loss: 0.4709\n","Epoch 12/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 86ms/step - accuracy: 0.8257 - loss: 0.3895 - val_accuracy: 0.7900 - val_loss: 0.4846\n","Epoch 13/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 82ms/step - accuracy: 0.8351 - loss: 0.3696 - val_accuracy: 0.7850 - val_loss: 0.5030\n","Epoch 14/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 81ms/step - accuracy: 0.8487 - loss: 0.3441 - val_accuracy: 0.8060 - val_loss: 0.4527\n","Epoch 15/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 81ms/step - accuracy: 0.8524 - loss: 0.3354 - val_accuracy: 0.7995 - val_loss: 0.4621\n","Epoch 16/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 101ms/step - accuracy: 0.8634 - loss: 0.3258 - val_accuracy: 0.7755 - val_loss: 0.5159\n","Epoch 17/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 200ms/step - accuracy: 0.8719 - loss: 0.2975 - val_accuracy: 0.7930 - val_loss: 0.4726\n","Epoch 18/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 209ms/step - accuracy: 0.8823 - loss: 0.2731 - val_accuracy: 0.8005 - val_loss: 0.4889\n","Epoch 19/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 206ms/step - accuracy: 0.8917 - loss: 0.2588 - val_accuracy: 0.7735 - val_loss: 0.5610\n","Epoch 20/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 207ms/step - accuracy: 0.9049 - loss: 0.2301 - val_accuracy: 0.7915 - val_loss: 0.5234\n","Epoch 21/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 194ms/step - accuracy: 0.9111 - loss: 0.2242 - val_accuracy: 0.7975 - val_loss: 0.5576\n","Epoch 22/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 214ms/step - accuracy: 0.9136 - loss: 0.2129 - val_accuracy: 0.7905 - val_loss: 0.5434\n","Epoch 23/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 214ms/step - accuracy: 0.9197 - loss: 0.2024 - val_accuracy: 0.8045 - val_loss: 0.5589\n","Epoch 24/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 210ms/step - accuracy: 0.9231 - loss: 0.1919 - val_accuracy: 0.7980 - val_loss: 0.5623\n","Epoch 25/25\n","\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 201ms/step - accuracy: 0.9345 - loss: 0.1679 - val_accuracy: 0.8070 - val_loss: 0.5627\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x2bbe5099e80>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"gsSiWEJY1BPB"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n"]}],"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('dataset\\\\malteser.jpg', target_size = (64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ED9KB3I54c1i"},"outputs":[{"name":"stdout","output_type":"stream","text":["dog\n"]}],"source":["print(prediction)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":0}
